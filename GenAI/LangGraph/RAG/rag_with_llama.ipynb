{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7813f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nomic.exe is installed in 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet -U langchain langchain_community tiktoken langchain-nomic \"nomic[local]\" langchain-ollama scikit-learn langgraph tavily-python bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607910c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-nomic in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.1.2 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-nomic) (3.5.3)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-nomic) (0.3.66)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.3.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-nomic) (10.4.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (9.1.2)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.4.4)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (4.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (1.33)\n",
      "Requirement already satisfied: click in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (8.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.3.1)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (20.0.0)\n",
      "Requirement already satisfied: loguru in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (0.7.3)\n",
      "Requirement already satisfied: rich in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (14.0.0)\n",
      "Requirement already satisfied: pyjwt in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.32.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.67.1)\n",
      "Requirement already satisfied: jsonlines in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from nomic<4.0.0,>=3.1.2->langchain-nomic) (2.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.23.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (3.10.18)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.28.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from pydantic>=2.7.4->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (2.33.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from requests->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from click->nomic<4.0.0,>=3.1.2->langchain-nomic) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from jsonlines->nomic<4.0.0,>=3.1.2->langchain-nomic) (25.3.0)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from loguru->nomic<4.0.0,>=3.1.2->langchain-nomic) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.9.0.post0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (2.19.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (0.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.1.2->langchain-nomic) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->nomic<4.0.0,>=3.1.2->langchain-nomic) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langchain-nomic) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35c026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "local_llm = \"llama3.2:3b-instruct-fp16\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, response_format=\"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df1a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sravy\\AppData\\Local\\Temp\\ipykernel_4824\\4277837698.py:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm_json_mode.predict(\"What is the capital of Tamilnadu?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Tamil Nadu is Chennai.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_json_mode.predict(\"What is the capital of Tamilnadu?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9993323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"tvly-dev-QRePeodaQjbVdRVnXUsMyTkD4Ztm9bQpTAVILY_API_KEY\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0abc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "Embedding texts: 100%|██████████| 28/28 [04:08<00:00,  8.87s/inputs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://tmobile.wd1.myworkdayjobs.com/en-US/External/job/Principal-Engineer--Software-Full-Stack_REQ309783-1\",\n",
    "    #\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    # \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "811e85fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'websearch'} {'datasource': 'websearch'} {'datasource': 'vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "### Router\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Prompt\n",
    "router_instructions = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "\n",
    "Use the vectorstore for questions on these topics. For all else, and especially for current events, use web-search.\n",
    "\n",
    "Return JSON with single key, datasource, that is 'websearch' or 'vectorstore' depending on the question.\"\"\"\n",
    "\n",
    "# Test router\n",
    "test_web_search = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [\n",
    "        HumanMessage(\n",
    "            content=\"Who is favored to win the NFC Championship game in the 2024 season?\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "test_web_search_2 = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [HumanMessage(content=\"What are the models released today for llama3.2?\")]\n",
    ")\n",
    "test_vector_store = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=router_instructions)]\n",
    "    + [HumanMessage(content=\"What are the types of agent memory?\")]\n",
    ")\n",
    "import re\n",
    "\n",
    "def extract_json(text):\n",
    "    match = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
    "    if match:\n",
    "        return json.loads(match.group(0))\n",
    "    raise ValueError(\"No JSON object found in text.\")\n",
    "\n",
    "print(\n",
    "    extract_json(test_web_search.content),\n",
    "    extract_json(test_web_search_2.content),\n",
    "    extract_json(test_vector_store.content),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e9f32cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding texts: 100%|██████████| 1/1 [00:00<00:00,  3.57inputs/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'binary_score': 'yes'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "# Doc grader instructions\n",
    "doc_grader_instructions = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "doc_grader_prompt = \"\"\"Here is the retrieved document: \\n\\n {document} \\n\\n Here is the user question: \\n\\n {question}. \n",
    "\n",
    "Read this carefully and objectively assess whether the document contains at least some information that is relevant to the question.\n",
    "\n",
    "Return JSON with single key, binary_score, that is 'yes' or 'no' score to indicate whether the document contains at least some information that is relevant to the question.\"\"\"\n",
    "\n",
    "# Test\n",
    "question = \"What is Chain of thought prompting?\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "doc_grader_prompt_formatted = doc_grader_prompt.format(\n",
    "    document=doc_txt, question=question\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=doc_grader_instructions)]\n",
    "    + [HumanMessage(content=doc_grader_prompt_formatted)]\n",
    ")\n",
    "json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f98080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding texts: 100%|██████████| 1/1 [00:00<00:00,  5.42inputs/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought (CoT) prompting is a technique used in natural language processing that generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. This method was first introduced by Wei et al. (2022) and has been further developed in various research papers, including Tree of Thoughts (Yao et al., 2023), which extends CoT by exploring multiple reasoning possibilities at each step. CoT prompting is particularly beneficial for complicated reasoning tasks, where it can improve the accuracy of model outputs.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "rag_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "\n",
    "Here is the context to use to answer the question:\n",
    "\n",
    "{context} \n",
    "\n",
    "Think carefully about the above context. \n",
    "\n",
    "Now, review the user question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Provide an answer to this questions using only the above context. \n",
    "\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Test\n",
    "docs = retriever.invoke(question)\n",
    "docs_txt = format_docs(docs)\n",
    "rag_prompt_formatted = rag_prompt.format(context=docs_txt, question=question)\n",
    "generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "print(generation.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab30b84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     27\u001b[39m hallucination_grader_prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33mFACTS: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{documents}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m STUDENT ANSWER: \u001b[39m\u001b[38;5;132;01m{generation}\u001b[39;00m\u001b[33m. \u001b[39m\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m \u001b[33mReturn only JSON output with two two keys, binary_score is \u001b[39m\u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno\u001b[39m\u001b[33m'\u001b[39m\u001b[33m score to indicate whether the STUDENT ANSWER is grounded in the FACTS. And a key, explanation, that contains an explanation of the score.\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Test using documents and generation from above\u001b[39;00m\n\u001b[32m     32\u001b[39m hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     documents=\u001b[43mdocs_txt\u001b[49m, generation=generation.content\n\u001b[32m     34\u001b[39m )\n\u001b[32m     35\u001b[39m result = llm_json_mode.invoke(\n\u001b[32m     36\u001b[39m     [SystemMessage(content=hallucination_grader_instructions)]\n\u001b[32m     37\u001b[39m     + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n\u001b[32m     38\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[31mNameError\u001b[39m: name 'docs_txt' is not defined"
     ]
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# Hallucination grader instructions\n",
    "hallucination_grader_instructions = \"\"\"\n",
    "\n",
    "You are a teacher grading a quiz. \n",
    "\n",
    "You will be given FACTS and a STUDENT ANSWER. \n",
    "\n",
    "Here is the grade criteria to follow:\n",
    "\n",
    "(1) Ensure the STUDENT ANSWER is grounded in the FACTS. \n",
    "\n",
    "(2) Ensure the STUDENT ANSWER does not contain \"hallucinated\" information outside the scope of the FACTS.\n",
    "\n",
    "Score:\n",
    "\n",
    "A score of yes means that the student's answer meets all of the criteria. This is the highest (best) score. \n",
    "\n",
    "A score of no means that the student's answer does not meet all of the criteria. This is the lowest possible score you can give.\n",
    "\n",
    "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "\n",
    "Avoid simply stating the correct answer at the outset.\"\"\"\n",
    "\n",
    "# Grader prompt\n",
    "hallucination_grader_prompt = \"\"\"FACTS: \\n\\n {documents} \\n\\n STUDENT ANSWER: {generation}. \n",
    "\n",
    "Return only JSON output with two two keys, binary_score is 'yes' or 'no' score to indicate whether the STUDENT ANSWER is grounded in the FACTS. And a key, explanation, that contains an explanation of the score.\"\"\"\n",
    "\n",
    "# Test using documents and generation from above\n",
    "hallucination_grader_prompt_formatted = hallucination_grader_prompt.format(\n",
    "    documents=docs_txt, generation=generation.content\n",
    ")\n",
    "result = llm_json_mode.invoke(\n",
    "    [SystemMessage(content=hallucination_grader_instructions)]\n",
    "    + [HumanMessage(content=hallucination_grader_prompt_formatted)]\n",
    ")\n",
    "print(result)\n",
    "#json.loads(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7339b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0b4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
