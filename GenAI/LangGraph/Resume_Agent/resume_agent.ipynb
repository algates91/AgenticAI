{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40f8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "local_llm = \"llama3.2:3b-instruct-fp16\"\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=local_llm, temperature=0, response_format=\"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4ec2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"tvly-dev-QRePeodaQjbVdRVnXUsMyTkD4Ztm9bQpTAVILY_API_KEY\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7aa82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SKLearnVectorStoreException",
     "evalue": "No data was added to SKLearnVectorStore.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSKLearnVectorStoreException\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m doc_splits = text_splitter.split_documents(docs_list)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Add to vectorDB\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m vectorstore = SKLearnVectorStore.from_documents(\n\u001b[32m     27\u001b[39m     documents=doc_splits,\n\u001b[32m     28\u001b[39m     embedding=NomicEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text-v1.5\u001b[39m\u001b[33m\"\u001b[39m, inference_mode=\u001b[33m\"\u001b[39m\u001b[33mlocal\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     29\u001b[39m )\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Create retriever\u001b[39;00m\n\u001b[32m     32\u001b[39m retriever = vectorstore.as_retriever(k=\u001b[32m3\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001b[39m, in \u001b[36mVectorStore.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, **kwargs)\u001b[39m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[32m    846\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m] = ids\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Lib\\site-packages\\langchain_community\\vectorstores\\sklearn.py:353\u001b[39m, in \u001b[36mSKLearnVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, persist_path, **kwargs)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m     **kwargs: Any,\n\u001b[32m    351\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mSKLearnVectorStore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    352\u001b[39m     vs = SKLearnVectorStore(embedding, persist_path=persist_path, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[43mvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m vs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Lib\\site-packages\\langchain_community\\vectorstores\\sklearn.py:209\u001b[39m, in \u001b[36mSKLearnVectorStore.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28mself\u001b[39m._metadatas.extend(metadatas \u001b[38;5;129;01mor\u001b[39;00m ([{}] * \u001b[38;5;28mlen\u001b[39m(_texts)))\n\u001b[32m    208\u001b[39m \u001b[38;5;28mself\u001b[39m._ids.extend(_ids)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sravy\\.pyenv\\pyenv-win\\versions\\3.11.0b4\\Lib\\site-packages\\langchain_community\\vectorstores\\sklearn.py:214\u001b[39m, in \u001b[36mSKLearnVectorStore._update_neighbors\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_neighbors\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._embeddings) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SKLearnVectorStoreException(\n\u001b[32m    215\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNo data was added to SKLearnVectorStore.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     \u001b[38;5;28mself\u001b[39m._embeddings_np = \u001b[38;5;28mself\u001b[39m._np.asarray(\u001b[38;5;28mself\u001b[39m._embeddings)\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m._neighbors.fit(\u001b[38;5;28mself\u001b[39m._embeddings_np)\n",
      "\u001b[31mSKLearnVectorStoreException\u001b[39m: No data was added to SKLearnVectorStore."
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "urls = [\n",
    "    \"https://tmobile.wd1.myworkdayjobs.com/en-US/External/job/Principal-Engineer--Software-Full-Stack_REQ309783-1\",\n",
    "    #\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    # \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split documents\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "#     chunk_size=1000, chunk_overlap=200\n",
    "# )\n",
    "# doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# # Add to vectorDB\n",
    "# vectorstore = SKLearnVectorStore.from_documents(\n",
    "#     documents=doc_splits,\n",
    "#     embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    "# )\n",
    "\n",
    "# # Create retriever\n",
    "# retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877680d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.0b4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
